{"cells":[{"cell_type":"markdown","metadata":{"id":"lMIBf4ZxS-uv"},"source":["**Keras MNIST PQT/QAT Tutorial**"]},{"cell_type":"markdown","metadata":{"id":"BKC7tS2XTqUq"},"source":["Load tensorflow library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LJ3sjxOjSLcK"},"outputs":[],"source":["import os \n","import tensorflow as tf\n","print(tf.__version__)\n","\n","!pip install tensorflow_model_optimization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YlQPbAAFI-ez"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","base_path = '/content/drive/MyDrive/Colab_Embedded2023'"]},{"cell_type":"markdown","metadata":{"id":"MgRyj5wmT3Pm"},"source":["Load dataset (MNIST)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4E2FoIUTLSr"},"outputs":[],"source":["cifar10 = tf.keras.datasets.cifar10\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","y_train = y_train.flatten()\n","y_test = y_test.flatten()\n"]},{"cell_type":"markdown","metadata":{"id":"_GzFOOZQUDQh"},"source":["Preprocessing dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7s5Q0ueTS7q"},"outputs":[],"source":["import numpy as np\n","input_shape = (32, 32, 3)\n","\n","x_train = x_train.reshape(x_train.shape[0], *input_shape)\n","x_train = x_train / 255.0\n","x_test = x_test.reshape(x_test.shape[0], *input_shape)\n","x_test = x_test / 255.0\n","\n","y_train = tf.one_hot(y_train.astype(np.int32), depth=10)\n","y_test = tf.one_hot(y_test.astype(np.int32), depth=10)\n"]},{"cell_type":"markdown","metadata":{"id":"u6euAfwxUYtz"},"source":["Define and train the baseline model "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bPgRbwDBUIZ6"},"outputs":[],"source":["batch_size = 64\n","epochs = 50\n","\n","\n","reg = tf.keras.regularizers.l2(1e-4)\n","\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(16, 3, padding='same', input_shape=input_shape, kernel_regularizer=reg),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.ReLU(),\n","    tf.keras.layers.Conv2D(16, 3, padding='same', kernel_regularizer=reg),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.ReLU(),\n","    tf.keras.layers.MaxPooling2D(),    \n","\n","    tf.keras.layers.Conv2D(32, 3, padding='same', kernel_regularizer=reg),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.ReLU(),\n","    tf.keras.layers.Conv2D(32, 3, padding='same', kernel_regularizer=reg),    \n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.ReLU(),\n","    tf.keras.layers.MaxPooling2D(),\n","\n","    tf.keras.layers.Conv2D(64, 3, padding='same', kernel_regularizer=reg),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.ReLU(),\n","    tf.keras.layers.Conv2D(64, 3, padding='same', kernel_regularizer=reg),    \n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.ReLU(),\n","    \n","    tf.keras.layers.GlobalAveragePooling2D(),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(10, activation='softmax', kernel_regularizer=reg)\n","])\n","\n","schedule = tf.keras.optimizers.schedules.CosineDecay(\n","    initial_learning_rate=1e-3, decay_steps=x_train.shape[0] * epochs // batch_size)\n","\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=schedule, weight_decay=0),\n","            loss='categorical_crossentropy', metrics=['acc'])\n","\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","datagen = ImageDataGenerator(\n","    rotation_range=15,\n","    horizontal_flip=True,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1\n","    #zoom_range=0.3\n","    )\n","\n","#history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n","history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n","                    steps_per_epoch = len(x_train) / batch_size, epochs=epochs, validation_data=(x_test, y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SuqOMmBZW1sZ"},"outputs":[],"source":["tf.keras.models.save_model(model, os.path.join(base_path, \"model.h5\"))\n","model.save_weights(os.path.join(base_path, \"model.weight\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R2Iq-lnRXVcJ"},"outputs":[],"source":["# Convert the model\n","converter = tf.lite.TFLiteConverter.from_keras_model(model) # path to the SavedModel directory\n","tflite_model = converter.convert()\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","\n","# Save the model.\n","with open(os.path.join(base_path, 'model.tflite'), 'wb') as f:\n","  f.write(tflite_model)"]},{"cell_type":"markdown","metadata":{"id":"BRjEbuqmP2m8"},"source":["Apply Quantization-aware Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GPI3q5Jdifb2"},"outputs":[],"source":["from tensorflow_model_optimization.quantization.keras import quantize_apply\n","from tensorflow_model_optimization.quantization.keras import quantize_annotate_layer\n","\n","batch_size = 64\n","epochs = 5\n","\n","reg = tf.keras.regularizers.l2(1e-4)\n","\n","model = tf.keras.models.Sequential([\n","    quantize_annotate_layer(tf.keras.layers.Conv2D(16, 3, padding='same', input_shape=input_shape, kernel_regularizer=reg)),\n","    quantize_annotate_layer(tf.keras.layers.BatchNormalization()),\n","    quantize_annotate_layer(tf.keras.layers.ReLU()),\n","    quantize_annotate_layer(tf.keras.layers.Conv2D(16, 3, padding='same', kernel_regularizer=reg)),\n","    quantize_annotate_layer(tf.keras.layers.BatchNormalization()),\n","    quantize_annotate_layer(tf.keras.layers.ReLU()),\n","    quantize_annotate_layer(tf.keras.layers.MaxPooling2D()),    \n","\n","    quantize_annotate_layer(tf.keras.layers.Conv2D(32, 3, padding='same', kernel_regularizer=reg)),\n","    quantize_annotate_layer(tf.keras.layers.BatchNormalization()),\n","    quantize_annotate_layer(tf.keras.layers.ReLU()),\n","    quantize_annotate_layer(tf.keras.layers.Conv2D(32, 3, padding='same', kernel_regularizer=reg)),    \n","    quantize_annotate_layer(tf.keras.layers.BatchNormalization()),\n","    quantize_annotate_layer(tf.keras.layers.ReLU()),\n","    quantize_annotate_layer(tf.keras.layers.MaxPooling2D()),\n","\n","    quantize_annotate_layer(tf.keras.layers.Conv2D(64, 3, padding='same', kernel_regularizer=reg)),\n","    quantize_annotate_layer(tf.keras.layers.BatchNormalization()),\n","    quantize_annotate_layer(tf.keras.layers.ReLU()),\n","    quantize_annotate_layer(tf.keras.layers.Conv2D(64, 3, padding='same', kernel_regularizer=reg)),    \n","    quantize_annotate_layer(tf.keras.layers.BatchNormalization()),\n","    quantize_annotate_layer(tf.keras.layers.ReLU()),\n","    \n","    quantize_annotate_layer(tf.keras.layers.GlobalAveragePooling2D()),\n","    quantize_annotate_layer(tf.keras.layers.Flatten()),\n","    quantize_annotate_layer(tf.keras.layers.Dense(10, activation='softmax', kernel_regularizer=reg))\n","])\n","\n","model.load_weights(os.path.join(base_path, \"model.weight\"))\n","\n","schedule = tf.keras.optimizers.schedules.CosineDecay(\n","    initial_learning_rate=1e-3, decay_steps=x_train.shape[0] * epochs // batch_size)\n","\n","\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","datagen = ImageDataGenerator(\n","    rotation_range=15,\n","    horizontal_flip=True,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1\n","    #zoom_range=0.3\n","    )\n","\n","\n","\n","quantized_model = quantize_apply(model)\n","quantized_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=schedule, weight_decay=0),\n","            loss='categorical_crossentropy', metrics=['acc'])\n","\n","quantized_model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n","                    steps_per_epoch = len(x_train) / batch_size, epochs=epochs, validation_data=(x_test, y_test))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JBjKfB0zGg2p"},"outputs":[],"source":["converter = tf.lite.TFLiteConverter.from_keras_model(quantized_model) # path to the SavedModel directory\n","\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","tflite_model = converter.convert()\n","\n","# Save the model.\n","with open(os.path.join(base_path, 'model_quant.tflite'), 'wb') as f:\n","  f.write(tflite_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JxG55qBiSJ7j"},"outputs":[],"source":["print(\"Float model in Kb:\", os.path.getsize(os.path.join(base_path, \"model.tflite\")) / float(2**10))\n","print(\"Quantized model in Kb:\",  os.path.getsize(os.path.join(base_path, \"model_quant.tflite\")) / float(2**10))\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
